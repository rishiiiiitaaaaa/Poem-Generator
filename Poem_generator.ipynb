{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzEhaXY9zKCg",
        "outputId": "f4d1a16d-8af6-45db-d903-26cd3c6b6304"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqPMMgaAzXX4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nR1Ss26izdID"
      },
      "outputs": [],
      "source": [
        "with open('/content/drive/My Drive/Colab Notebooks/data/robert_frost.txt') as story:\n",
        "  story_data = story.read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HPKZNmGnzhmJ",
        "outputId": "a568bffb-de1f-46cf-9112-a3a24b401511"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Two roads diverged in a yellow wood,\n",
            "And sorry I could not travel both\n",
            "And be one traveler, long I stood\n",
            "And looked down one as far as I could\n",
            "To where it bent in the undergrowth;\n",
            "\n",
            "Then took the other, as just as fair,\n",
            "And having perhaps the better claim,\n",
            "Because it was grassy and wanted wear;\n",
            "Though as for that the passing there\n",
            "Had worn them really about the same,\n",
            "\n",
            "And both that morning equally lay\n",
            "In leaves no step had trodden black.\n",
            "Oh, I kept the first for another day!\n",
            "Yet knowing how way leads on to way,\n",
            "I doubted if I should ever come back.\n",
            "\n",
            "I shall be telling this with a sigh\n",
            "Somewhere ages and ages hence:\n",
            "Two roads diverged in a wood, and I—\n",
            "I took the one less traveled by,\n",
            "And that has made all the difference.\n",
            "\n",
            "Whose woods these are I think I know.   \n",
            "His house is in the village though;   \n",
            "He will not see me stopping here   \n",
            "To watch his woods fill up with snow.   \n",
            "\n",
            "My little horse must think it queer   \n",
            "To stop without a farmhouse near   \n",
            "Between the woods and frozen lake   \n",
            "The darkest evening of the year.   \n",
            "\n",
            "He gives his harness bells a shake   \n",
            "To ask if there is some mistake.   \n",
            "The only other sound’s the sweep   \n",
            "Of easy wind and downy flake.   \n",
            "\n",
            "The woods are lovely, dark and deep,   \n",
            "But I have promises to keep,   \n",
            "And miles to go before I sleep,   \n",
            "And miles to go before I sleep.\n",
            "\n",
            "When I see birches bend to left and right\n",
            "Across the lines of straighter darker trees,\n",
            "I like to think some boy's been swinging them.\n",
            "But swinging doesn't bend them down to stay\n",
            "As ice-storms do. Often you must have seen them\n",
            "Loaded with ice a sunny winter morning\n",
            "After a rain. They click upon themselves\n",
            "As the breeze rises, and turn many-colored\n",
            "As the stir cracks and crazes their enamel.\n",
            "Soon the sun's warmth makes them shed crystal shells\n",
            "Shattering and avalanching on the snow-crust—\n",
            "Such heaps of broken glass to sweep away\n",
            "You'd think the inner dome of heaven had fallen.\n",
            "They are dragged to the withered bracken by the load,\n",
            "And they seem not to break; though once they are bowed\n",
            "So low for long, they never right themselves:\n",
            "You may see their trunks arching in the woods\n",
            "Years afterwards, trailing their leaves on the ground\n",
            "Like girls on hands and knees that throw their hair\n",
            "Before them over their heads to dry in the sun.\n",
            "But I was going to say when Truth broke in\n",
            "With all her matter-of-fact about the ice-storm\n",
            "I should prefer to have some boy bend them\n",
            "As he went out and in to fetch the cows—\n",
            "Some boy too far from town to learn baseball,\n",
            "Whose only play was what he found himself,\n",
            "Summer or winter, and could play alone.\n",
            "One by one he subdued his father's trees\n",
            "By riding them down over and over again\n",
            "Until he took the stiffness out of them,\n",
            "And not one but hung limp, not one was left\n",
            "For him to conquer. He learned all there was\n",
            "To learn about not launching out too soon\n",
            "And so not carrying the tree away\n",
            "Clear to the ground. He always kept his poise\n",
            "To the top branches, climbing carefully\n",
            "With the same pains you use to fill a cup\n",
            "Up to the brim, and even above the brim.\n",
            "Then he flung outward, feet first, with a swish,\n",
            "Kicking his way down through the air to the ground.\n",
            "So was I once myself a swinger of birches.\n",
            "And so I dream of going back to be.\n",
            "It's when I'm weary of considerations,\n",
            "And life is too much like a pathless wood\n",
            "Where your face burns and tickles with the cobwebs\n",
            "Broken across it, and one eye is weeping\n",
            "From a twig's having lashed across it open.\n",
            "I'd like to get away from earth awhile\n",
            "And then come back to it and begin over.\n",
            "May no fate willfully misunderstand me\n",
            "And half grant what I wish and snatch me away\n",
            "Not to return. Earth's the right place for love:\n",
            "I don't know where it's likely to go better.\n",
            "I'd like to go by climbing a birch tree,\n",
            "And climb black branches up a snow-white trunk\n",
            "Toward heaven, till the tree could bear no more,\n",
            "But dipped its top and set me down again.\n",
            "That would be good both going and coming back.\n",
            "One could do worse than be a swinger of birches.\n",
            "\n",
            "Before man came to blow it right\n",
            "     The wind once blew itself untaught,\n",
            "And did its loudest day and night\n",
            "     In any rough place where it caught.\n",
            " \n",
            "Man came to tell it what was wrong:\n",
            "     It hadn’t found the place to blow;\n",
            "It blew too hard—the aim was song.\n",
            "     And listen—how it ought to go!\n",
            " \n",
            "He took a little in his mouth,\n",
            "     And held it long enough for north\n",
            "To be converted into south,\n",
            "     And then by measure blew it forth.\n",
            " \n",
            "By measure. It was word and note,\n",
            "     The wind the wind had meant to be—\n",
            "A little through the lips and throat.\n",
            "     The aim was song—the wind could see.\n",
            "\n",
            "The city had withdrawn into itself\n",
            "And left at last the country to the country;\n",
            "When between whirls of snow not come to lie\n",
            "And whirls of foliage not yet laid, there drove\n",
            "A stranger to our yard, who looked the city,\n",
            "Yet did in country fashion in that there\n",
            "He sat and waited till he drew us out\n",
            "A-buttoning coats to ask him who he was.\n",
            "He proved to be the city come again\n",
            "To look for something it had left behind\n",
            "And could not do without and keep its Christmas.\n",
            "He asked if I would sell my Christmas trees;\n",
            "My woods—the young fir balsams like a place\n",
            "Where houses all are churches and have spires.\n",
            "I hadn’t thought of them as Christmas Trees.\n",
            "I doubt if I was tempted for a moment\n",
            "To sell them off their feet to go in cars\n",
            "And leave the slope behind the house all bare,\n",
            "Where the sun shines now no warmer than the moon.\n",
            "I’d hate to have them know it if I was.\n",
            "Yet more I’d hate to hold my trees except\n",
            "As others hold theirs or refuse for them,\n",
            "Beyond the time of profitable growth,\n",
            "The trial by market everything must come to.\n",
            "I dallied so much with the thought of selling.\n",
            "Then whether from mistaken courtesy\n",
            "And fear of seeming short of speech, or whether\n",
            "From hope of hearing good of what was mine, I said,\n",
            "“There aren’t enough to be worth while.”\n",
            "“I could soon tell how many they would cut,\n",
            "You let me look them over.”\n",
            "\n",
            "                                                     “You could look.\n",
            "But don’t expect I’m going to let you have them.”\n",
            "Pasture they spring in, some in clumps too close\n",
            "That lop each other of boughs, but not a few\n",
            "Quite solitary and having equal boughs\n",
            "All round and round. The latter he nodded “Yes” to,\n",
            "Or paused to say beneath some lovelier one,\n",
            "With a buyer’s moderation, “That would do.”\n",
            "I thought so too, but wasn’t there to say so.\n",
            "We climbed the pasture on the south, crossed over,\n",
            "And came down on the north. He said, “A thousand.”\n",
            "\n",
            "“A thousand Christmas trees!—at what apiece?”\n",
            "\n",
            "He felt some need of softening that to me:\n",
            "“A thousand trees would come to thirty dollars.”\n",
            "\n",
            "Then I was certain I had never meant\n",
            "To let him have them. Never show surprise!\n",
            "But thirty dollars seemed so small beside\n",
            "The extent of pasture I should strip, three cents\n",
            "(For that was all they figured out apiece),\n",
            "Three cents so small beside the dollar friends\n",
            "I should be writing to within the hour\n",
            "Would pay in cities for good trees like those,\n",
            "Regular vestry-trees whole Sunday Schools\n",
            "Could hang enough on to pick off enough.\n",
            "A thousand Christmas trees I didn’t know I had!\n",
            "Worth three cents more to give away than sell,\n",
            "As may be shown by a simple calculation.\n",
            "Too bad I couldn’t lay one in a letter.\n",
            "I can’t help wishing I could send you one,\n",
            "In wishing you herewith a Merry Christmas.\n"
          ]
        }
      ],
      "source": [
        "print(story_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GRlZwpq-zjmF"
      },
      "outputs": [],
      "source": [
        "import re                                # Regular expressions to use sub function for replacing the useless text from the data\n",
        "\n",
        "def clean_text(text):\n",
        "  text = re.sub(r',', '', text)\n",
        "  text = re.sub(r'\\'', '',  text)\n",
        "  text = re.sub(r'\\\"', '', text)\n",
        "  text = re.sub(r'\\(', '', text)\n",
        "  text = re.sub(r'\\)', '', text)\n",
        "  text = re.sub(r'\\n', '', text)\n",
        "  text = re.sub(r'“', '', text)\n",
        "  text = re.sub(r'”', '', text)\n",
        "  text = re.sub(r'’', '', text)\n",
        "  text = re.sub(r'\\.', '', text)\n",
        "  text = re.sub(r';', '', text)\n",
        "  text = re.sub(r':', '', text)\n",
        "  text = re.sub(r'\\-', '', text)\n",
        "\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54neYVMmz6iH",
        "outputId": "7d427cf9-4180-4a48-cde3-7f4ca2f425dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['two roads diverged in a yellow wood,', 'and sorry i could not travel both', 'and be one traveler, long i stood', 'and looked down one as far as i could', 'to where it bent in the undergrowth;', '', 'then took the other, as just as fair,', 'and having perhaps the better claim,', 'because it was grassy and wanted wear;', 'though as for that the passing there', 'had worn them really about the same,', '', 'and both that morning equally lay', 'in leaves no step had trodden black.', 'oh, i kept the first for another day!', 'yet knowing how way leads on to way,', 'i doubted if i should ever come back.', '', 'i shall be telling this with a sigh', 'somewhere ages and ages hence:', 'two roads diverged in a wood, and i—', 'i took the one less traveled by,', 'and that has made all the difference.', '', 'whose woods these are i think i know.   ', 'his house is in the village though;   ', 'he will not see me stopping here   ', 'to watch his woods fill up with snow.   ', '', 'my little horse must think it queer   ', 'to stop without a farmhouse near   ', 'between the woods and frozen lake   ', 'the darkest evening of the year.   ', '', 'he gives his harness bells a shake   ', 'to ask if there is some mistake.   ', 'the only other sound’s the sweep   ', 'of easy wind and downy flake.   ', '', 'the woods are lovely, dark and deep,   ', 'but i have promises to keep,   ', 'and miles to go before i sleep,   ', 'and miles to go before i sleep.', '', 'when i see birches bend to left and right', 'across the lines of straighter darker trees,', \"i like to think some boy's been swinging them.\", \"but swinging doesn't bend them down to stay\", 'as ice-storms do. often you must have seen them', 'loaded with ice a sunny winter morning', 'after a rain. they click upon themselves', 'as the breeze rises, and turn many-colored', 'as the stir cracks and crazes their enamel.', \"soon the sun's warmth makes them shed crystal shells\", 'shattering and avalanching on the snow-crust—', 'such heaps of broken glass to sweep away', \"you'd think the inner dome of heaven had fallen.\", 'they are dragged to the withered bracken by the load,', 'and they seem not to break; though once they are bowed', 'so low for long, they never right themselves:', 'you may see their trunks arching in the woods', 'years afterwards, trailing their leaves on the ground', 'like girls on hands and knees that throw their hair', 'before them over their heads to dry in the sun.', 'but i was going to say when truth broke in', 'with all her matter-of-fact about the ice-storm', 'i should prefer to have some boy bend them', 'as he went out and in to fetch the cows—', 'some boy too far from town to learn baseball,', 'whose only play was what he found himself,', 'summer or winter, and could play alone.', \"one by one he subdued his father's trees\", 'by riding them down over and over again', 'until he took the stiffness out of them,', 'and not one but hung limp, not one was left', 'for him to conquer. he learned all there was', 'to learn about not launching out too soon', 'and so not carrying the tree away', 'clear to the ground. he always kept his poise', 'to the top branches, climbing carefully', 'with the same pains you use to fill a cup', 'up to the brim, and even above the brim.', 'then he flung outward, feet first, with a swish,', 'kicking his way down through the air to the ground.', 'so was i once myself a swinger of birches.', 'and so i dream of going back to be.', \"it's when i'm weary of considerations,\", 'and life is too much like a pathless wood', 'where your face burns and tickles with the cobwebs', 'broken across it, and one eye is weeping', \"from a twig's having lashed across it open.\", \"i'd like to get away from earth awhile\", 'and then come back to it and begin over.', 'may no fate willfully misunderstand me', 'and half grant what i wish and snatch me away', \"not to return. earth's the right place for love:\", \"i don't know where it's likely to go better.\", \"i'd like to go by climbing a birch tree,\", 'and climb black branches up a snow-white trunk', 'toward heaven, till the tree could bear no more,', 'but dipped its top and set me down again.', 'that would be good both going and coming back.', 'one could do worse than be a swinger of birches.', '', 'before man came to blow it right', '     the wind once blew itself untaught,', 'and did its loudest day and night', '     in any rough place where it caught.', ' ', 'man came to tell it what was wrong:', '     it hadn’t found the place to blow;', 'it blew too hard—the aim was song.', '     and listen—how it ought to go!', ' ', 'he took a little in his mouth,', '     and held it long enough for north', 'to be converted into south,', '     and then by measure blew it forth.', ' ', 'by measure. it was word and note,', '     the wind the wind had meant to be—', 'a little through the lips and throat.', '     the aim was song—the wind could see.', '', 'the city had withdrawn into itself', 'and left at last the country to the country;', 'when between whirls of snow not come to lie', 'and whirls of foliage not yet laid, there drove', 'a stranger to our yard, who looked the city,', 'yet did in country fashion in that there', 'he sat and waited till he drew us out', 'a-buttoning coats to ask him who he was.', 'he proved to be the city come again', 'to look for something it had left behind', 'and could not do without and keep its christmas.', 'he asked if i would sell my christmas trees;', 'my woods—the young fir balsams like a place', 'where houses all are churches and have spires.', 'i hadn’t thought of them as christmas trees.', 'i doubt if i was tempted for a moment', 'to sell them off their feet to go in cars', 'and leave the slope behind the house all bare,', 'where the sun shines now no warmer than the moon.', 'i’d hate to have them know it if i was.', 'yet more i’d hate to hold my trees except', 'as others hold theirs or refuse for them,', 'beyond the time of profitable growth,', 'the trial by market everything must come to.', 'i dallied so much with the thought of selling.', 'then whether from mistaken courtesy', 'and fear of seeming short of speech, or whether', 'from hope of hearing good of what was mine, i said,', '“there aren’t enough to be worth while.”', '“i could soon tell how many they would cut,', 'you let me look them over.”', '', '                                                     “you could look.', 'but don’t expect i’m going to let you have them.”', 'pasture they spring in, some in clumps too close', 'that lop each other of boughs, but not a few', 'quite solitary and having equal boughs', 'all round and round. the latter he nodded “yes” to,', 'or paused to say beneath some lovelier one,', 'with a buyer’s moderation, “that would do.”', 'i thought so too, but wasn’t there to say so.', 'we climbed the pasture on the south, crossed over,', 'and came down on the north. he said, “a thousand.”', '', '“a thousand christmas trees!—at what apiece?”', '', 'he felt some need of softening that to me:', '“a thousand trees would come to thirty dollars.”', '', 'then i was certain i had never meant', 'to let him have them. never show surprise!', 'but thirty dollars seemed so small beside', 'the extent of pasture i should strip, three cents', '(for that was all they figured out apiece),', 'three cents so small beside the dollar friends', 'i should be writing to within the hour', 'would pay in cities for good trees like those,', 'regular vestry-trees whole sunday schools', 'could hang enough on to pick off enough.', 'a thousand christmas trees i didn’t know i had!', 'worth three cents more to give away than sell,', 'as may be shown by a simple calculation.', 'too bad i couldn’t lay one in a letter.', 'i can’t help wishing i could send you one,', 'in wishing you herewith a merry christmas.']\n",
            "\n",
            "two roads diverged in a yellow wood\n",
            "and sorry i could not travel both\n",
            "and be one traveler long i stood\n",
            "and looked down one as far as i could\n",
            "to where it bent in the undergrowth\n",
            "\n",
            "then took the other as just as fair\n",
            "and having perhaps the better claim\n",
            "because it was grassy and wanted wear\n",
            "though as for that the passing there\n",
            "had worn them really about the same\n",
            "\n",
            "and both that morning equally lay\n",
            "in leaves no step had trodden black\n",
            "oh i kept the first for another day!\n",
            "yet knowing how way leads on to way\n",
            "i doubted if i should ever come back\n",
            "\n",
            "i shall be telling this with a sigh\n",
            "somewhere ages and ages hence\n",
            "two roads diverged in a wood and i—\n",
            "i took the one less traveled by\n",
            "and that has made all the difference\n",
            "\n",
            "whose woods these are i think i know   \n",
            "his house is in the village though   \n",
            "he will not see me stopping here   \n",
            "to watch his woods fill up with snow   \n",
            "\n",
            "my little horse must think it queer   \n",
            "to stop without a farmhouse near   \n",
            "between the woods and frozen lake   \n",
            "the darkest evening of the year   \n",
            "\n",
            "he gives his harness bells a shake   \n",
            "to ask if there is some mistake   \n",
            "the only other sounds the sweep   \n",
            "of easy wind and downy flake   \n",
            "\n",
            "the woods are lovely dark and deep   \n",
            "but i have promises to keep   \n",
            "and miles to go before i sleep   \n",
            "and miles to go before i sleep\n",
            "\n",
            "when i see birches bend to left and right\n",
            "across the lines of straighter darker trees\n",
            "i like to think some boys been swinging them\n",
            "but swinging doesnt bend them down to stay\n",
            "as icestorms do often you must have seen them\n",
            "loaded with ice a sunny winter morning\n",
            "after a rain they click upon themselves\n",
            "as the breeze rises and turn manycolored\n",
            "as the stir cracks and crazes their enamel\n",
            "soon the suns warmth makes them shed crystal shells\n",
            "shattering and avalanching on the snowcrust—\n",
            "such heaps of broken glass to sweep away\n",
            "youd think the inner dome of heaven had fallen\n",
            "they are dragged to the withered bracken by the load\n",
            "and they seem not to break though once they are bowed\n",
            "so low for long they never right themselves\n",
            "you may see their trunks arching in the woods\n",
            "years afterwards trailing their leaves on the ground\n",
            "like girls on hands and knees that throw their hair\n",
            "before them over their heads to dry in the sun\n",
            "but i was going to say when truth broke in\n",
            "with all her matteroffact about the icestorm\n",
            "i should prefer to have some boy bend them\n",
            "as he went out and in to fetch the cows—\n",
            "some boy too far from town to learn baseball\n",
            "whose only play was what he found himself\n",
            "summer or winter and could play alone\n",
            "one by one he subdued his fathers trees\n",
            "by riding them down over and over again\n",
            "until he took the stiffness out of them\n",
            "and not one but hung limp not one was left\n",
            "for him to conquer he learned all there was\n",
            "to learn about not launching out too soon\n",
            "and so not carrying the tree away\n",
            "clear to the ground he always kept his poise\n",
            "to the top branches climbing carefully\n",
            "with the same pains you use to fill a cup\n",
            "up to the brim and even above the brim\n",
            "then he flung outward feet first with a swish\n",
            "kicking his way down through the air to the ground\n",
            "so was i once myself a swinger of birches\n",
            "and so i dream of going back to be\n",
            "its when im weary of considerations\n",
            "and life is too much like a pathless wood\n",
            "where your face burns and tickles with the cobwebs\n",
            "broken across it and one eye is weeping\n",
            "from a twigs having lashed across it open\n",
            "id like to get away from earth awhile\n",
            "and then come back to it and begin over\n",
            "may no fate willfully misunderstand me\n",
            "and half grant what i wish and snatch me away\n",
            "not to return earths the right place for love\n",
            "i dont know where its likely to go better\n",
            "id like to go by climbing a birch tree\n",
            "and climb black branches up a snowwhite trunk\n",
            "toward heaven till the tree could bear no more\n",
            "but dipped its top and set me down again\n",
            "that would be good both going and coming back\n",
            "one could do worse than be a swinger of birches\n",
            "\n",
            "before man came to blow it right\n",
            "     the wind once blew itself untaught\n",
            "and did its loudest day and night\n",
            "     in any rough place where it caught\n",
            " \n",
            "man came to tell it what was wrong\n",
            "     it hadnt found the place to blow\n",
            "it blew too hard—the aim was song\n",
            "     and listen—how it ought to go!\n",
            " \n",
            "he took a little in his mouth\n",
            "     and held it long enough for north\n",
            "to be converted into south\n",
            "     and then by measure blew it forth\n",
            " \n",
            "by measure it was word and note\n",
            "     the wind the wind had meant to be—\n",
            "a little through the lips and throat\n",
            "     the aim was song—the wind could see\n",
            "\n",
            "the city had withdrawn into itself\n",
            "and left at last the country to the country\n",
            "when between whirls of snow not come to lie\n",
            "and whirls of foliage not yet laid there drove\n",
            "a stranger to our yard who looked the city\n",
            "yet did in country fashion in that there\n",
            "he sat and waited till he drew us out\n",
            "abuttoning coats to ask him who he was\n",
            "he proved to be the city come again\n",
            "to look for something it had left behind\n",
            "and could not do without and keep its christmas\n",
            "he asked if i would sell my christmas trees\n",
            "my woods—the young fir balsams like a place\n",
            "where houses all are churches and have spires\n",
            "i hadnt thought of them as christmas trees\n",
            "i doubt if i was tempted for a moment\n",
            "to sell them off their feet to go in cars\n",
            "and leave the slope behind the house all bare\n",
            "where the sun shines now no warmer than the moon\n",
            "id hate to have them know it if i was\n",
            "yet more id hate to hold my trees except\n",
            "as others hold theirs or refuse for them\n",
            "beyond the time of profitable growth\n",
            "the trial by market everything must come to\n",
            "i dallied so much with the thought of selling\n",
            "then whether from mistaken courtesy\n",
            "and fear of seeming short of speech or whether\n",
            "from hope of hearing good of what was mine i said\n",
            "there arent enough to be worth while\n",
            "i could soon tell how many they would cut\n",
            "you let me look them over\n",
            "\n",
            "                                                     you could look\n",
            "but dont expect im going to let you have them\n",
            "pasture they spring in some in clumps too close\n",
            "that lop each other of boughs but not a few\n",
            "quite solitary and having equal boughs\n",
            "all round and round the latter he nodded yes to\n",
            "or paused to say beneath some lovelier one\n",
            "with a buyers moderation that would do\n",
            "i thought so too but wasnt there to say so\n",
            "we climbed the pasture on the south crossed over\n",
            "and came down on the north he said a thousand\n",
            "\n",
            "a thousand christmas trees!—at what apiece?\n",
            "\n",
            "he felt some need of softening that to me\n",
            "a thousand trees would come to thirty dollars\n",
            "\n",
            "then i was certain i had never meant\n",
            "to let him have them never show surprise!\n",
            "but thirty dollars seemed so small beside\n",
            "the extent of pasture i should strip three cents\n",
            "for that was all they figured out apiece\n",
            "three cents so small beside the dollar friends\n",
            "i should be writing to within the hour\n",
            "would pay in cities for good trees like those\n",
            "regular vestrytrees whole sunday schools\n",
            "could hang enough on to pick off enough\n",
            "a thousand christmas trees i didnt know i had!\n",
            "worth three cents more to give away than sell\n",
            "as may be shown by a simple calculation\n",
            "too bad i couldnt lay one in a letter\n",
            "i cant help wishing i could send you one\n",
            "in wishing you herewith a merry christmas\n"
          ]
        }
      ],
      "source": [
        "# cleaning the data\n",
        "lower_data = story_data.lower()           # Converting the string to lower case to get uniformity\n",
        "\n",
        "split_data = lower_data.splitlines()      # Splitting the data to get every line seperately but this will give the list of uncleaned data\n",
        "\n",
        "print(split_data)\n",
        "\n",
        "final = ''                                # initiating a argument with blank string to hold the values of final cleaned data\n",
        "\n",
        "for line in split_data:\n",
        "  line = clean_text(line)\n",
        "  final += '\\n' + line\n",
        "\n",
        "print(final)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ssxjSxc4z8gP",
        "outputId": "a68f1aae-7ebc-4ed5-cb35-90aa60eb3315"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['', 'two roads diverged in a yellow wood', 'and sorry i could not travel both', 'and be one traveler long i stood', 'and looked down one as far as i could', 'to where it bent in the undergrowth', '', 'then took the other as just as fair', 'and having perhaps the better claim', 'because it was grassy and wanted wear', 'though as for that the passing there', 'had worn them really about the same', '', 'and both that morning equally lay', 'in leaves no step had trodden black', 'oh i kept the first for another day!', 'yet knowing how way leads on to way', 'i doubted if i should ever come back', '', 'i shall be telling this with a sigh', 'somewhere ages and ages hence', 'two roads diverged in a wood and i—', 'i took the one less traveled by', 'and that has made all the difference', '', 'whose woods these are i think i know   ', 'his house is in the village though   ', 'he will not see me stopping here   ', 'to watch his woods fill up with snow   ', '', 'my little horse must think it queer   ', 'to stop without a farmhouse near   ', 'between the woods and frozen lake   ', 'the darkest evening of the year   ', '', 'he gives his harness bells a shake   ', 'to ask if there is some mistake   ', 'the only other sounds the sweep   ', 'of easy wind and downy flake   ', '', 'the woods are lovely dark and deep   ', 'but i have promises to keep   ', 'and miles to go before i sleep   ', 'and miles to go before i sleep', '', 'when i see birches bend to left and right', 'across the lines of straighter darker trees', 'i like to think some boys been swinging them', 'but swinging doesnt bend them down to stay', 'as icestorms do often you must have seen them', 'loaded with ice a sunny winter morning', 'after a rain they click upon themselves', 'as the breeze rises and turn manycolored', 'as the stir cracks and crazes their enamel', 'soon the suns warmth makes them shed crystal shells', 'shattering and avalanching on the snowcrust—', 'such heaps of broken glass to sweep away', 'youd think the inner dome of heaven had fallen', 'they are dragged to the withered bracken by the load', 'and they seem not to break though once they are bowed', 'so low for long they never right themselves', 'you may see their trunks arching in the woods', 'years afterwards trailing their leaves on the ground', 'like girls on hands and knees that throw their hair', 'before them over their heads to dry in the sun', 'but i was going to say when truth broke in', 'with all her matteroffact about the icestorm', 'i should prefer to have some boy bend them', 'as he went out and in to fetch the cows—', 'some boy too far from town to learn baseball', 'whose only play was what he found himself', 'summer or winter and could play alone', 'one by one he subdued his fathers trees', 'by riding them down over and over again', 'until he took the stiffness out of them', 'and not one but hung limp not one was left', 'for him to conquer he learned all there was', 'to learn about not launching out too soon', 'and so not carrying the tree away', 'clear to the ground he always kept his poise', 'to the top branches climbing carefully', 'with the same pains you use to fill a cup', 'up to the brim and even above the brim', 'then he flung outward feet first with a swish', 'kicking his way down through the air to the ground', 'so was i once myself a swinger of birches', 'and so i dream of going back to be', 'its when im weary of considerations', 'and life is too much like a pathless wood', 'where your face burns and tickles with the cobwebs', 'broken across it and one eye is weeping', 'from a twigs having lashed across it open', 'id like to get away from earth awhile', 'and then come back to it and begin over', 'may no fate willfully misunderstand me', 'and half grant what i wish and snatch me away', 'not to return earths the right place for love', 'i dont know where its likely to go better', 'id like to go by climbing a birch tree', 'and climb black branches up a snowwhite trunk', 'toward heaven till the tree could bear no more', 'but dipped its top and set me down again', 'that would be good both going and coming back', 'one could do worse than be a swinger of birches', '', 'before man came to blow it right', '     the wind once blew itself untaught', 'and did its loudest day and night', '     in any rough place where it caught', ' ', 'man came to tell it what was wrong', '     it hadnt found the place to blow', 'it blew too hard—the aim was song', '     and listen—how it ought to go!', ' ', 'he took a little in his mouth', '     and held it long enough for north', 'to be converted into south', '     and then by measure blew it forth', ' ', 'by measure it was word and note', '     the wind the wind had meant to be—', 'a little through the lips and throat', '     the aim was song—the wind could see', '', 'the city had withdrawn into itself', 'and left at last the country to the country', 'when between whirls of snow not come to lie', 'and whirls of foliage not yet laid there drove', 'a stranger to our yard who looked the city', 'yet did in country fashion in that there', 'he sat and waited till he drew us out', 'abuttoning coats to ask him who he was', 'he proved to be the city come again', 'to look for something it had left behind', 'and could not do without and keep its christmas', 'he asked if i would sell my christmas trees', 'my woods—the young fir balsams like a place', 'where houses all are churches and have spires', 'i hadnt thought of them as christmas trees', 'i doubt if i was tempted for a moment', 'to sell them off their feet to go in cars', 'and leave the slope behind the house all bare', 'where the sun shines now no warmer than the moon', 'id hate to have them know it if i was', 'yet more id hate to hold my trees except', 'as others hold theirs or refuse for them', 'beyond the time of profitable growth', 'the trial by market everything must come to', 'i dallied so much with the thought of selling', 'then whether from mistaken courtesy', 'and fear of seeming short of speech or whether', 'from hope of hearing good of what was mine i said', 'there arent enough to be worth while', 'i could soon tell how many they would cut', 'you let me look them over', '', '                                                     you could look', 'but dont expect im going to let you have them', 'pasture they spring in some in clumps too close', 'that lop each other of boughs but not a few', 'quite solitary and having equal boughs', 'all round and round the latter he nodded yes to', 'or paused to say beneath some lovelier one', 'with a buyers moderation that would do', 'i thought so too but wasnt there to say so', 'we climbed the pasture on the south crossed over', 'and came down on the north he said a thousand', '', 'a thousand christmas trees!—at what apiece?', '', 'he felt some need of softening that to me', 'a thousand trees would come to thirty dollars', '', 'then i was certain i had never meant', 'to let him have them never show surprise!', 'but thirty dollars seemed so small beside', 'the extent of pasture i should strip three cents', 'for that was all they figured out apiece', 'three cents so small beside the dollar friends', 'i should be writing to within the hour', 'would pay in cities for good trees like those', 'regular vestrytrees whole sunday schools', 'could hang enough on to pick off enough', 'a thousand christmas trees i didnt know i had!', 'worth three cents more to give away than sell', 'as may be shown by a simple calculation', 'too bad i couldnt lay one in a letter', 'i cant help wishing i could send you one', 'in wishing you herewith a merry christmas']\n"
          ]
        }
      ],
      "source": [
        "final_data = final.split('\\n')\n",
        " # splitting again to get list of cleaned and splitted data ready to be processed\n",
        "print(final_data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jHA6NfiS0B0N"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "#These are used for text tokenization and padding sequences to ensure they have the same length, respectively."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76osbBER0HEh"
      },
      "outputs": [],
      "source": [
        "# Instantiating the Tokenizer\n",
        "max_vocab = 1000000\n",
        "tokenizer = Tokenizer(num_words=max_vocab) #instance of the tokenizer\n",
        "tokenizer.fit_on_texts(final_data) #updates the internal vocabulary based on the text data provided"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eq3u7_zd0Luc",
        "outputId": "11d7f4cd-d29e-49aa-9218-6647590af7d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "544\n",
            "{'the': 1, 'to': 2, 'and': 3, 'i': 4, 'a': 5, 'of': 6, 'in': 7, 'he': 8, 'it': 9, 'was': 10, 'them': 11, 'not': 12, 'one': 13, 'as': 14, 'could': 15, 'for': 16, 'be': 17, 'that': 18, 'with': 19, 'by': 20, 'but': 21, 'trees': 22, 'so': 23, 'had': 24, 'you': 25, 'they': 26, 'there': 27, 'on': 28, 'all': 29, 'his': 30, 'some': 31, 'have': 32, 'like': 33, 'too': 34, 'down': 35, 'where': 36, 'then': 37, 'come': 38, 'me': 39, 'go': 40, 'their': 41, 'over': 42, 'would': 43, 'christmas': 44, 'if': 45, 'woods': 46, 'are': 47, 'wind': 48, 'away': 49, 'out': 50, 'from': 51, 'what': 52, 'its': 53, 'took': 54, 'no': 55, 'yet': 56, 'should': 57, 'back': 58, 'think': 59, 'know': 60, 'is': 61, 'see': 62, 'my': 63, 'before': 64, 'when': 65, 'left': 66, 'right': 67, 'do': 68, 'going': 69, 'or': 70, 'id': 71, 'place': 72, 'enough': 73, 'thousand': 74, 'wood': 75, 'both': 76, 'long': 77, 'other': 78, 'having': 79, 'though': 80, 'about': 81, 'way': 82, 'up': 83, 'little': 84, 'must': 85, 'birches': 86, 'bend': 87, 'across': 88, 'soon': 89, 'once': 90, 'never': 91, 'may': 92, 'ground': 93, 'say': 94, 'again': 95, 'him': 96, 'tree': 97, 'more': 98, 'good': 99, 'than': 100, 'came': 101, 'blew': 102, 'city': 103, 'country': 104, 'look': 105, 'sell': 106, 'thought': 107, 'let': 108, 'pasture': 109, 'three': 110, 'cents': 111, 'two': 112, 'roads': 113, 'diverged': 114, 'looked': 115, 'far': 116, 'better': 117, 'same': 118, 'morning': 119, 'lay': 120, 'leaves': 121, 'black': 122, 'kept': 123, 'first': 124, 'day': 125, 'how': 126, 'ages': 127, 'whose': 128, 'house': 129, 'fill': 130, 'snow': 131, 'without': 132, 'between': 133, 'ask': 134, 'only': 135, 'sweep': 136, 'keep': 137, 'miles': 138, 'sleep': 139, 'swinging': 140, 'winter': 141, 'themselves': 142, 'broken': 143, 'heaven': 144, 'sun': 145, 'boy': 146, 'learn': 147, 'play': 148, 'found': 149, 'top': 150, 'branches': 151, 'climbing': 152, 'brim': 153, 'feet': 154, 'through': 155, 'swinger': 156, 'im': 157, 'much': 158, 'dont': 159, 'till': 160, 'man': 161, 'blow': 162, 'itself': 163, 'did': 164, 'tell': 165, 'hadnt': 166, 'aim': 167, 'north': 168, 'into': 169, 'south': 170, 'measure': 171, 'meant': 172, 'whirls': 173, 'who': 174, 'behind': 175, 'off': 176, 'hate': 177, 'hold': 178, 'whether': 179, 'said': 180, 'worth': 181, 'boughs': 182, 'round': 183, 'apiece': 184, 'thirty': 185, 'dollars': 186, 'small': 187, 'beside': 188, 'wishing': 189, 'yellow': 190, 'sorry': 191, 'travel': 192, 'traveler': 193, 'stood': 194, 'bent': 195, 'undergrowth': 196, 'just': 197, 'fair': 198, 'perhaps': 199, 'claim': 200, 'because': 201, 'grassy': 202, 'wanted': 203, 'wear': 204, 'passing': 205, 'worn': 206, 'really': 207, 'equally': 208, 'step': 209, 'trodden': 210, 'oh': 211, 'another': 212, 'knowing': 213, 'leads': 214, 'doubted': 215, 'ever': 216, 'shall': 217, 'telling': 218, 'this': 219, 'sigh': 220, 'somewhere': 221, 'hence': 222, 'i—': 223, 'less': 224, 'traveled': 225, 'has': 226, 'made': 227, 'difference': 228, 'these': 229, 'village': 230, 'will': 231, 'stopping': 232, 'here': 233, 'watch': 234, 'horse': 235, 'queer': 236, 'stop': 237, 'farmhouse': 238, 'near': 239, 'frozen': 240, 'lake': 241, 'darkest': 242, 'evening': 243, 'year': 244, 'gives': 245, 'harness': 246, 'bells': 247, 'shake': 248, 'mistake': 249, 'sounds': 250, 'easy': 251, 'downy': 252, 'flake': 253, 'lovely': 254, 'dark': 255, 'deep': 256, 'promises': 257, 'lines': 258, 'straighter': 259, 'darker': 260, 'boys': 261, 'been': 262, 'doesnt': 263, 'stay': 264, 'icestorms': 265, 'often': 266, 'seen': 267, 'loaded': 268, 'ice': 269, 'sunny': 270, 'after': 271, 'rain': 272, 'click': 273, 'upon': 274, 'breeze': 275, 'rises': 276, 'turn': 277, 'manycolored': 278, 'stir': 279, 'cracks': 280, 'crazes': 281, 'enamel': 282, 'suns': 283, 'warmth': 284, 'makes': 285, 'shed': 286, 'crystal': 287, 'shells': 288, 'shattering': 289, 'avalanching': 290, 'snowcrust—': 291, 'such': 292, 'heaps': 293, 'glass': 294, 'youd': 295, 'inner': 296, 'dome': 297, 'fallen': 298, 'dragged': 299, 'withered': 300, 'bracken': 301, 'load': 302, 'seem': 303, 'break': 304, 'bowed': 305, 'low': 306, 'trunks': 307, 'arching': 308, 'years': 309, 'afterwards': 310, 'trailing': 311, 'girls': 312, 'hands': 313, 'knees': 314, 'throw': 315, 'hair': 316, 'heads': 317, 'dry': 318, 'truth': 319, 'broke': 320, 'her': 321, 'matteroffact': 322, 'icestorm': 323, 'prefer': 324, 'went': 325, 'fetch': 326, 'cows—': 327, 'town': 328, 'baseball': 329, 'himself': 330, 'summer': 331, 'alone': 332, 'subdued': 333, 'fathers': 334, 'riding': 335, 'until': 336, 'stiffness': 337, 'hung': 338, 'limp': 339, 'conquer': 340, 'learned': 341, 'launching': 342, 'carrying': 343, 'clear': 344, 'always': 345, 'poise': 346, 'carefully': 347, 'pains': 348, 'use': 349, 'cup': 350, 'even': 351, 'above': 352, 'flung': 353, 'outward': 354, 'swish': 355, 'kicking': 356, 'air': 357, 'myself': 358, 'dream': 359, 'weary': 360, 'considerations': 361, 'life': 362, 'pathless': 363, 'your': 364, 'face': 365, 'burns': 366, 'tickles': 367, 'cobwebs': 368, 'eye': 369, 'weeping': 370, 'twigs': 371, 'lashed': 372, 'open': 373, 'get': 374, 'earth': 375, 'awhile': 376, 'begin': 377, 'fate': 378, 'willfully': 379, 'misunderstand': 380, 'half': 381, 'grant': 382, 'wish': 383, 'snatch': 384, 'return': 385, 'earths': 386, 'love': 387, 'likely': 388, 'birch': 389, 'climb': 390, 'snowwhite': 391, 'trunk': 392, 'toward': 393, 'bear': 394, 'dipped': 395, 'set': 396, 'coming': 397, 'worse': 398, 'untaught': 399, 'loudest': 400, 'night': 401, 'any': 402, 'rough': 403, 'caught': 404, 'wrong': 405, 'hard—the': 406, 'song': 407, 'listen—how': 408, 'ought': 409, 'mouth': 410, 'held': 411, 'converted': 412, 'forth': 413, 'word': 414, 'note': 415, 'be—': 416, 'lips': 417, 'throat': 418, 'song—the': 419, 'withdrawn': 420, 'at': 421, 'last': 422, 'lie': 423, 'foliage': 424, 'laid': 425, 'drove': 426, 'stranger': 427, 'our': 428, 'yard': 429, 'fashion': 430, 'sat': 431, 'waited': 432, 'drew': 433, 'us': 434, 'abuttoning': 435, 'coats': 436, 'proved': 437, 'something': 438, 'asked': 439, 'woods—the': 440, 'young': 441, 'fir': 442, 'balsams': 443, 'houses': 444, 'churches': 445, 'spires': 446, 'doubt': 447, 'tempted': 448, 'moment': 449, 'cars': 450, 'leave': 451, 'slope': 452, 'bare': 453, 'shines': 454, 'now': 455, 'warmer': 456, 'moon': 457, 'except': 458, 'others': 459, 'theirs': 460, 'refuse': 461, 'beyond': 462, 'time': 463, 'profitable': 464, 'growth': 465, 'trial': 466, 'market': 467, 'everything': 468, 'dallied': 469, 'selling': 470, 'mistaken': 471, 'courtesy': 472, 'fear': 473, 'seeming': 474, 'short': 475, 'speech': 476, 'hope': 477, 'hearing': 478, 'mine': 479, 'arent': 480, 'while': 481, 'many': 482, 'cut': 483, 'expect': 484, 'spring': 485, 'clumps': 486, 'close': 487, 'lop': 488, 'each': 489, 'few': 490, 'quite': 491, 'solitary': 492, 'equal': 493, 'latter': 494, 'nodded': 495, 'yes': 496, 'paused': 497, 'beneath': 498, 'lovelier': 499, 'buyers': 500, 'moderation': 501, 'wasnt': 502, 'we': 503, 'climbed': 504, 'crossed': 505, '—at': 506, 'felt': 507, 'need': 508, 'softening': 509, 'certain': 510, 'show': 511, 'surprise': 512, 'seemed': 513, 'extent': 514, 'strip': 515, 'figured': 516, 'dollar': 517, 'friends': 518, 'writing': 519, 'within': 520, 'hour': 521, 'pay': 522, 'cities': 523, 'those': 524, 'regular': 525, 'vestrytrees': 526, 'whole': 527, 'sunday': 528, 'schools': 529, 'hang': 530, 'pick': 531, 'didnt': 532, 'give': 533, 'shown': 534, 'simple': 535, 'calculation': 536, 'bad': 537, 'couldnt': 538, 'letter': 539, 'cant': 540, 'help': 541, 'send': 542, 'herewith': 543, 'merry': 544}\n",
            "545\n"
          ]
        }
      ],
      "source": [
        "# Getting the total number of words of the data.\n",
        "word2idx = tokenizer.word_index #retrieves the dictionary mapping words to their indices.\n",
        "print(len(word2idx))\n",
        "print(word2idx)\n",
        "vocab_size = len(word2idx) + 1\n",
        "# Adding 1 to the vocab_size because the index starts from 1 not 0. This will make it uniform when using it further\n",
        "print(vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnxcyMLR0SA5"
      },
      "outputs": [],
      "source": [
        "input_seq = []\n",
        "\n",
        "for line in final_data:\n",
        "  token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "  #converts the line into a sequence of integers.\n",
        "  for i in range(1, len(token_list)):\n",
        "    n_gram_seq = token_list[:i+1]\n",
        "    input_seq.append(n_gram_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOxdBGio0T5c",
        "outputId": "7a19db08-92cd-44a7-ebe1-2724109ca377"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[112, 113], [112, 113, 114], [112, 113, 114, 7], [112, 113, 114, 7, 5], [112, 113, 114, 7, 5, 190], [112, 113, 114, 7, 5, 190, 75], [3, 191], [3, 191, 4], [3, 191, 4, 15], [3, 191, 4, 15, 12], [3, 191, 4, 15, 12, 192], [3, 191, 4, 15, 12, 192, 76], [3, 17], [3, 17, 13], [3, 17, 13, 193], [3, 17, 13, 193, 77], [3, 17, 13, 193, 77, 4], [3, 17, 13, 193, 77, 4, 194], [3, 115], [3, 115, 35], [3, 115, 35, 13], [3, 115, 35, 13, 14], [3, 115, 35, 13, 14, 116], [3, 115, 35, 13, 14, 116, 14], [3, 115, 35, 13, 14, 116, 14, 4], [3, 115, 35, 13, 14, 116, 14, 4, 15], [2, 36], [2, 36, 9], [2, 36, 9, 195], [2, 36, 9, 195, 7], [2, 36, 9, 195, 7, 1], [2, 36, 9, 195, 7, 1, 196], [37, 54], [37, 54, 1], [37, 54, 1, 78], [37, 54, 1, 78, 14], [37, 54, 1, 78, 14, 197], [37, 54, 1, 78, 14, 197, 14], [37, 54, 1, 78, 14, 197, 14, 198], [3, 79], [3, 79, 199], [3, 79, 199, 1], [3, 79, 199, 1, 117], [3, 79, 199, 1, 117, 200], [201, 9], [201, 9, 10], [201, 9, 10, 202], [201, 9, 10, 202, 3], [201, 9, 10, 202, 3, 203], [201, 9, 10, 202, 3, 203, 204], [80, 14], [80, 14, 16], [80, 14, 16, 18], [80, 14, 16, 18, 1], [80, 14, 16, 18, 1, 205], [80, 14, 16, 18, 1, 205, 27], [24, 206], [24, 206, 11], [24, 206, 11, 207], [24, 206, 11, 207, 81], [24, 206, 11, 207, 81, 1], [24, 206, 11, 207, 81, 1, 118], [3, 76], [3, 76, 18], [3, 76, 18, 119], [3, 76, 18, 119, 208], [3, 76, 18, 119, 208, 120], [7, 121], [7, 121, 55], [7, 121, 55, 209], [7, 121, 55, 209, 24], [7, 121, 55, 209, 24, 210], [7, 121, 55, 209, 24, 210, 122], [211, 4], [211, 4, 123], [211, 4, 123, 1], [211, 4, 123, 1, 124], [211, 4, 123, 1, 124, 16], [211, 4, 123, 1, 124, 16, 212], [211, 4, 123, 1, 124, 16, 212, 125], [56, 213], [56, 213, 126], [56, 213, 126, 82], [56, 213, 126, 82, 214], [56, 213, 126, 82, 214, 28], [56, 213, 126, 82, 214, 28, 2], [56, 213, 126, 82, 214, 28, 2, 82], [4, 215], [4, 215, 45], [4, 215, 45, 4], [4, 215, 45, 4, 57], [4, 215, 45, 4, 57, 216], [4, 215, 45, 4, 57, 216, 38], [4, 215, 45, 4, 57, 216, 38, 58], [4, 217], [4, 217, 17], [4, 217, 17, 218], [4, 217, 17, 218, 219], [4, 217, 17, 218, 219, 19], [4, 217, 17, 218, 219, 19, 5], [4, 217, 17, 218, 219, 19, 5, 220], [221, 127], [221, 127, 3], [221, 127, 3, 127], [221, 127, 3, 127, 222], [112, 113], [112, 113, 114], [112, 113, 114, 7], [112, 113, 114, 7, 5], [112, 113, 114, 7, 5, 75], [112, 113, 114, 7, 5, 75, 3], [112, 113, 114, 7, 5, 75, 3, 223], [4, 54], [4, 54, 1], [4, 54, 1, 13], [4, 54, 1, 13, 224], [4, 54, 1, 13, 224, 225], [4, 54, 1, 13, 224, 225, 20], [3, 18], [3, 18, 226], [3, 18, 226, 227], [3, 18, 226, 227, 29], [3, 18, 226, 227, 29, 1], [3, 18, 226, 227, 29, 1, 228], [128, 46], [128, 46, 229], [128, 46, 229, 47], [128, 46, 229, 47, 4], [128, 46, 229, 47, 4, 59], [128, 46, 229, 47, 4, 59, 4], [128, 46, 229, 47, 4, 59, 4, 60], [30, 129], [30, 129, 61], [30, 129, 61, 7], [30, 129, 61, 7, 1], [30, 129, 61, 7, 1, 230], [30, 129, 61, 7, 1, 230, 80], [8, 231], [8, 231, 12], [8, 231, 12, 62], [8, 231, 12, 62, 39], [8, 231, 12, 62, 39, 232], [8, 231, 12, 62, 39, 232, 233], [2, 234], [2, 234, 30], [2, 234, 30, 46], [2, 234, 30, 46, 130], [2, 234, 30, 46, 130, 83], [2, 234, 30, 46, 130, 83, 19], [2, 234, 30, 46, 130, 83, 19, 131], [63, 84], [63, 84, 235], [63, 84, 235, 85], [63, 84, 235, 85, 59], [63, 84, 235, 85, 59, 9], [63, 84, 235, 85, 59, 9, 236], [2, 237], [2, 237, 132], [2, 237, 132, 5], [2, 237, 132, 5, 238], [2, 237, 132, 5, 238, 239], [133, 1], [133, 1, 46], [133, 1, 46, 3], [133, 1, 46, 3, 240], [133, 1, 46, 3, 240, 241], [1, 242], [1, 242, 243], [1, 242, 243, 6], [1, 242, 243, 6, 1], [1, 242, 243, 6, 1, 244], [8, 245], [8, 245, 30], [8, 245, 30, 246], [8, 245, 30, 246, 247], [8, 245, 30, 246, 247, 5], [8, 245, 30, 246, 247, 5, 248], [2, 134], [2, 134, 45], [2, 134, 45, 27], [2, 134, 45, 27, 61], [2, 134, 45, 27, 61, 31], [2, 134, 45, 27, 61, 31, 249], [1, 135], [1, 135, 78], [1, 135, 78, 250], [1, 135, 78, 250, 1], [1, 135, 78, 250, 1, 136], [6, 251], [6, 251, 48], [6, 251, 48, 3], [6, 251, 48, 3, 252], [6, 251, 48, 3, 252, 253], [1, 46], [1, 46, 47], [1, 46, 47, 254], [1, 46, 47, 254, 255], [1, 46, 47, 254, 255, 3], [1, 46, 47, 254, 255, 3, 256], [21, 4], [21, 4, 32], [21, 4, 32, 257], [21, 4, 32, 257, 2], [21, 4, 32, 257, 2, 137], [3, 138], [3, 138, 2], [3, 138, 2, 40], [3, 138, 2, 40, 64], [3, 138, 2, 40, 64, 4], [3, 138, 2, 40, 64, 4, 139], [3, 138], [3, 138, 2], [3, 138, 2, 40], [3, 138, 2, 40, 64], [3, 138, 2, 40, 64, 4], [3, 138, 2, 40, 64, 4, 139], [65, 4], [65, 4, 62], [65, 4, 62, 86], [65, 4, 62, 86, 87], [65, 4, 62, 86, 87, 2], [65, 4, 62, 86, 87, 2, 66], [65, 4, 62, 86, 87, 2, 66, 3], [65, 4, 62, 86, 87, 2, 66, 3, 67], [88, 1], [88, 1, 258], [88, 1, 258, 6], [88, 1, 258, 6, 259], [88, 1, 258, 6, 259, 260], [88, 1, 258, 6, 259, 260, 22], [4, 33], [4, 33, 2], [4, 33, 2, 59], [4, 33, 2, 59, 31], [4, 33, 2, 59, 31, 261], [4, 33, 2, 59, 31, 261, 262], [4, 33, 2, 59, 31, 261, 262, 140], [4, 33, 2, 59, 31, 261, 262, 140, 11], [21, 140], [21, 140, 263], [21, 140, 263, 87], [21, 140, 263, 87, 11], [21, 140, 263, 87, 11, 35], [21, 140, 263, 87, 11, 35, 2], [21, 140, 263, 87, 11, 35, 2, 264], [14, 265], [14, 265, 68], [14, 265, 68, 266], [14, 265, 68, 266, 25], [14, 265, 68, 266, 25, 85], [14, 265, 68, 266, 25, 85, 32], [14, 265, 68, 266, 25, 85, 32, 267], [14, 265, 68, 266, 25, 85, 32, 267, 11], [268, 19], [268, 19, 269], [268, 19, 269, 5], [268, 19, 269, 5, 270], [268, 19, 269, 5, 270, 141], [268, 19, 269, 5, 270, 141, 119], [271, 5], [271, 5, 272], [271, 5, 272, 26], [271, 5, 272, 26, 273], [271, 5, 272, 26, 273, 274], [271, 5, 272, 26, 273, 274, 142], [14, 1], [14, 1, 275], [14, 1, 275, 276], [14, 1, 275, 276, 3], [14, 1, 275, 276, 3, 277], [14, 1, 275, 276, 3, 277, 278], [14, 1], [14, 1, 279], [14, 1, 279, 280], [14, 1, 279, 280, 3], [14, 1, 279, 280, 3, 281], [14, 1, 279, 280, 3, 281, 41], [14, 1, 279, 280, 3, 281, 41, 282], [89, 1], [89, 1, 283], [89, 1, 283, 284], [89, 1, 283, 284, 285], [89, 1, 283, 284, 285, 11], [89, 1, 283, 284, 285, 11, 286], [89, 1, 283, 284, 285, 11, 286, 287], [89, 1, 283, 284, 285, 11, 286, 287, 288], [289, 3], [289, 3, 290], [289, 3, 290, 28], [289, 3, 290, 28, 1], [289, 3, 290, 28, 1, 291], [292, 293], [292, 293, 6], [292, 293, 6, 143], [292, 293, 6, 143, 294], [292, 293, 6, 143, 294, 2], [292, 293, 6, 143, 294, 2, 136], [292, 293, 6, 143, 294, 2, 136, 49], [295, 59], [295, 59, 1], [295, 59, 1, 296], [295, 59, 1, 296, 297], [295, 59, 1, 296, 297, 6], [295, 59, 1, 296, 297, 6, 144], [295, 59, 1, 296, 297, 6, 144, 24], [295, 59, 1, 296, 297, 6, 144, 24, 298], [26, 47], [26, 47, 299], [26, 47, 299, 2], [26, 47, 299, 2, 1], [26, 47, 299, 2, 1, 300], [26, 47, 299, 2, 1, 300, 301], [26, 47, 299, 2, 1, 300, 301, 20], [26, 47, 299, 2, 1, 300, 301, 20, 1], [26, 47, 299, 2, 1, 300, 301, 20, 1, 302], [3, 26], [3, 26, 303], [3, 26, 303, 12], [3, 26, 303, 12, 2], [3, 26, 303, 12, 2, 304], [3, 26, 303, 12, 2, 304, 80], [3, 26, 303, 12, 2, 304, 80, 90], [3, 26, 303, 12, 2, 304, 80, 90, 26], [3, 26, 303, 12, 2, 304, 80, 90, 26, 47], [3, 26, 303, 12, 2, 304, 80, 90, 26, 47, 305], [23, 306], [23, 306, 16], [23, 306, 16, 77], [23, 306, 16, 77, 26], [23, 306, 16, 77, 26, 91], [23, 306, 16, 77, 26, 91, 67], [23, 306, 16, 77, 26, 91, 67, 142], [25, 92], [25, 92, 62], [25, 92, 62, 41], [25, 92, 62, 41, 307], [25, 92, 62, 41, 307, 308], [25, 92, 62, 41, 307, 308, 7], [25, 92, 62, 41, 307, 308, 7, 1], [25, 92, 62, 41, 307, 308, 7, 1, 46], [309, 310], [309, 310, 311], [309, 310, 311, 41], [309, 310, 311, 41, 121], [309, 310, 311, 41, 121, 28], [309, 310, 311, 41, 121, 28, 1], [309, 310, 311, 41, 121, 28, 1, 93], [33, 312], [33, 312, 28], [33, 312, 28, 313], [33, 312, 28, 313, 3], [33, 312, 28, 313, 3, 314], [33, 312, 28, 313, 3, 314, 18], [33, 312, 28, 313, 3, 314, 18, 315], [33, 312, 28, 313, 3, 314, 18, 315, 41], [33, 312, 28, 313, 3, 314, 18, 315, 41, 316], [64, 11], [64, 11, 42], [64, 11, 42, 41], [64, 11, 42, 41, 317], [64, 11, 42, 41, 317, 2], [64, 11, 42, 41, 317, 2, 318], [64, 11, 42, 41, 317, 2, 318, 7], [64, 11, 42, 41, 317, 2, 318, 7, 1], [64, 11, 42, 41, 317, 2, 318, 7, 1, 145], [21, 4], [21, 4, 10], [21, 4, 10, 69], [21, 4, 10, 69, 2], [21, 4, 10, 69, 2, 94], [21, 4, 10, 69, 2, 94, 65], [21, 4, 10, 69, 2, 94, 65, 319], [21, 4, 10, 69, 2, 94, 65, 319, 320], [21, 4, 10, 69, 2, 94, 65, 319, 320, 7], [19, 29], [19, 29, 321], [19, 29, 321, 322], [19, 29, 321, 322, 81], [19, 29, 321, 322, 81, 1], [19, 29, 321, 322, 81, 1, 323], [4, 57], [4, 57, 324], [4, 57, 324, 2], [4, 57, 324, 2, 32], [4, 57, 324, 2, 32, 31], [4, 57, 324, 2, 32, 31, 146], [4, 57, 324, 2, 32, 31, 146, 87], [4, 57, 324, 2, 32, 31, 146, 87, 11], [14, 8], [14, 8, 325], [14, 8, 325, 50], [14, 8, 325, 50, 3], [14, 8, 325, 50, 3, 7], [14, 8, 325, 50, 3, 7, 2], [14, 8, 325, 50, 3, 7, 2, 326], [14, 8, 325, 50, 3, 7, 2, 326, 1], [14, 8, 325, 50, 3, 7, 2, 326, 1, 327], [31, 146], [31, 146, 34], [31, 146, 34, 116], [31, 146, 34, 116, 51], [31, 146, 34, 116, 51, 328], [31, 146, 34, 116, 51, 328, 2], [31, 146, 34, 116, 51, 328, 2, 147], [31, 146, 34, 116, 51, 328, 2, 147, 329], [128, 135], [128, 135, 148], [128, 135, 148, 10], [128, 135, 148, 10, 52], [128, 135, 148, 10, 52, 8], [128, 135, 148, 10, 52, 8, 149], [128, 135, 148, 10, 52, 8, 149, 330], [331, 70], [331, 70, 141], [331, 70, 141, 3], [331, 70, 141, 3, 15], [331, 70, 141, 3, 15, 148], [331, 70, 141, 3, 15, 148, 332], [13, 20], [13, 20, 13], [13, 20, 13, 8], [13, 20, 13, 8, 333], [13, 20, 13, 8, 333, 30], [13, 20, 13, 8, 333, 30, 334], [13, 20, 13, 8, 333, 30, 334, 22], [20, 335], [20, 335, 11], [20, 335, 11, 35], [20, 335, 11, 35, 42], [20, 335, 11, 35, 42, 3], [20, 335, 11, 35, 42, 3, 42], [20, 335, 11, 35, 42, 3, 42, 95], [336, 8], [336, 8, 54], [336, 8, 54, 1], [336, 8, 54, 1, 337], [336, 8, 54, 1, 337, 50], [336, 8, 54, 1, 337, 50, 6], [336, 8, 54, 1, 337, 50, 6, 11], [3, 12], [3, 12, 13], [3, 12, 13, 21], [3, 12, 13, 21, 338], [3, 12, 13, 21, 338, 339], [3, 12, 13, 21, 338, 339, 12], [3, 12, 13, 21, 338, 339, 12, 13], [3, 12, 13, 21, 338, 339, 12, 13, 10], [3, 12, 13, 21, 338, 339, 12, 13, 10, 66], [16, 96], [16, 96, 2], [16, 96, 2, 340], [16, 96, 2, 340, 8], [16, 96, 2, 340, 8, 341], [16, 96, 2, 340, 8, 341, 29], [16, 96, 2, 340, 8, 341, 29, 27], [16, 96, 2, 340, 8, 341, 29, 27, 10], [2, 147], [2, 147, 81], [2, 147, 81, 12], [2, 147, 81, 12, 342], [2, 147, 81, 12, 342, 50], [2, 147, 81, 12, 342, 50, 34], [2, 147, 81, 12, 342, 50, 34, 89], [3, 23], [3, 23, 12], [3, 23, 12, 343], [3, 23, 12, 343, 1], [3, 23, 12, 343, 1, 97], [3, 23, 12, 343, 1, 97, 49], [344, 2], [344, 2, 1], [344, 2, 1, 93], [344, 2, 1, 93, 8], [344, 2, 1, 93, 8, 345], [344, 2, 1, 93, 8, 345, 123], [344, 2, 1, 93, 8, 345, 123, 30], [344, 2, 1, 93, 8, 345, 123, 30, 346], [2, 1], [2, 1, 150], [2, 1, 150, 151], [2, 1, 150, 151, 152], [2, 1, 150, 151, 152, 347], [19, 1], [19, 1, 118], [19, 1, 118, 348], [19, 1, 118, 348, 25], [19, 1, 118, 348, 25, 349], [19, 1, 118, 348, 25, 349, 2], [19, 1, 118, 348, 25, 349, 2, 130], [19, 1, 118, 348, 25, 349, 2, 130, 5], [19, 1, 118, 348, 25, 349, 2, 130, 5, 350], [83, 2], [83, 2, 1], [83, 2, 1, 153], [83, 2, 1, 153, 3], [83, 2, 1, 153, 3, 351], [83, 2, 1, 153, 3, 351, 352], [83, 2, 1, 153, 3, 351, 352, 1], [83, 2, 1, 153, 3, 351, 352, 1, 153], [37, 8], [37, 8, 353], [37, 8, 353, 354], [37, 8, 353, 354, 154], [37, 8, 353, 354, 154, 124], [37, 8, 353, 354, 154, 124, 19], [37, 8, 353, 354, 154, 124, 19, 5], [37, 8, 353, 354, 154, 124, 19, 5, 355], [356, 30], [356, 30, 82], [356, 30, 82, 35], [356, 30, 82, 35, 155], [356, 30, 82, 35, 155, 1], [356, 30, 82, 35, 155, 1, 357], [356, 30, 82, 35, 155, 1, 357, 2], [356, 30, 82, 35, 155, 1, 357, 2, 1], [356, 30, 82, 35, 155, 1, 357, 2, 1, 93], [23, 10], [23, 10, 4], [23, 10, 4, 90], [23, 10, 4, 90, 358], [23, 10, 4, 90, 358, 5], [23, 10, 4, 90, 358, 5, 156], [23, 10, 4, 90, 358, 5, 156, 6], [23, 10, 4, 90, 358, 5, 156, 6, 86], [3, 23], [3, 23, 4], [3, 23, 4, 359], [3, 23, 4, 359, 6], [3, 23, 4, 359, 6, 69], [3, 23, 4, 359, 6, 69, 58], [3, 23, 4, 359, 6, 69, 58, 2], [3, 23, 4, 359, 6, 69, 58, 2, 17], [53, 65], [53, 65, 157], [53, 65, 157, 360], [53, 65, 157, 360, 6], [53, 65, 157, 360, 6, 361], [3, 362], [3, 362, 61], [3, 362, 61, 34], [3, 362, 61, 34, 158], [3, 362, 61, 34, 158, 33], [3, 362, 61, 34, 158, 33, 5], [3, 362, 61, 34, 158, 33, 5, 363], [3, 362, 61, 34, 158, 33, 5, 363, 75], [36, 364], [36, 364, 365], [36, 364, 365, 366], [36, 364, 365, 366, 3], [36, 364, 365, 366, 3, 367], [36, 364, 365, 366, 3, 367, 19], [36, 364, 365, 366, 3, 367, 19, 1], [36, 364, 365, 366, 3, 367, 19, 1, 368], [143, 88], [143, 88, 9], [143, 88, 9, 3], [143, 88, 9, 3, 13], [143, 88, 9, 3, 13, 369], [143, 88, 9, 3, 13, 369, 61], [143, 88, 9, 3, 13, 369, 61, 370], [51, 5], [51, 5, 371], [51, 5, 371, 79], [51, 5, 371, 79, 372], [51, 5, 371, 79, 372, 88], [51, 5, 371, 79, 372, 88, 9], [51, 5, 371, 79, 372, 88, 9, 373], [71, 33], [71, 33, 2], [71, 33, 2, 374], [71, 33, 2, 374, 49], [71, 33, 2, 374, 49, 51], [71, 33, 2, 374, 49, 51, 375], [71, 33, 2, 374, 49, 51, 375, 376], [3, 37], [3, 37, 38], [3, 37, 38, 58], [3, 37, 38, 58, 2], [3, 37, 38, 58, 2, 9], [3, 37, 38, 58, 2, 9, 3], [3, 37, 38, 58, 2, 9, 3, 377], [3, 37, 38, 58, 2, 9, 3, 377, 42], [92, 55], [92, 55, 378], [92, 55, 378, 379], [92, 55, 378, 379, 380], [92, 55, 378, 379, 380, 39], [3, 381], [3, 381, 382], [3, 381, 382, 52], [3, 381, 382, 52, 4], [3, 381, 382, 52, 4, 383], [3, 381, 382, 52, 4, 383, 3], [3, 381, 382, 52, 4, 383, 3, 384], [3, 381, 382, 52, 4, 383, 3, 384, 39], [3, 381, 382, 52, 4, 383, 3, 384, 39, 49], [12, 2], [12, 2, 385], [12, 2, 385, 386], [12, 2, 385, 386, 1], [12, 2, 385, 386, 1, 67], [12, 2, 385, 386, 1, 67, 72], [12, 2, 385, 386, 1, 67, 72, 16], [12, 2, 385, 386, 1, 67, 72, 16, 387], [4, 159], [4, 159, 60], [4, 159, 60, 36], [4, 159, 60, 36, 53], [4, 159, 60, 36, 53, 388], [4, 159, 60, 36, 53, 388, 2], [4, 159, 60, 36, 53, 388, 2, 40], [4, 159, 60, 36, 53, 388, 2, 40, 117], [71, 33], [71, 33, 2], [71, 33, 2, 40], [71, 33, 2, 40, 20], [71, 33, 2, 40, 20, 152], [71, 33, 2, 40, 20, 152, 5], [71, 33, 2, 40, 20, 152, 5, 389], [71, 33, 2, 40, 20, 152, 5, 389, 97], [3, 390], [3, 390, 122], [3, 390, 122, 151], [3, 390, 122, 151, 83], [3, 390, 122, 151, 83, 5], [3, 390, 122, 151, 83, 5, 391], [3, 390, 122, 151, 83, 5, 391, 392], [393, 144], [393, 144, 160], [393, 144, 160, 1], [393, 144, 160, 1, 97], [393, 144, 160, 1, 97, 15], [393, 144, 160, 1, 97, 15, 394], [393, 144, 160, 1, 97, 15, 394, 55], [393, 144, 160, 1, 97, 15, 394, 55, 98], [21, 395], [21, 395, 53], [21, 395, 53, 150], [21, 395, 53, 150, 3], [21, 395, 53, 150, 3, 396], [21, 395, 53, 150, 3, 396, 39], [21, 395, 53, 150, 3, 396, 39, 35], [21, 395, 53, 150, 3, 396, 39, 35, 95], [18, 43], [18, 43, 17], [18, 43, 17, 99], [18, 43, 17, 99, 76], [18, 43, 17, 99, 76, 69], [18, 43, 17, 99, 76, 69, 3], [18, 43, 17, 99, 76, 69, 3, 397], [18, 43, 17, 99, 76, 69, 3, 397, 58], [13, 15], [13, 15, 68], [13, 15, 68, 398], [13, 15, 68, 398, 100], [13, 15, 68, 398, 100, 17], [13, 15, 68, 398, 100, 17, 5], [13, 15, 68, 398, 100, 17, 5, 156], [13, 15, 68, 398, 100, 17, 5, 156, 6], [13, 15, 68, 398, 100, 17, 5, 156, 6, 86], [64, 161], [64, 161, 101], [64, 161, 101, 2], [64, 161, 101, 2, 162], [64, 161, 101, 2, 162, 9], [64, 161, 101, 2, 162, 9, 67], [1, 48], [1, 48, 90], [1, 48, 90, 102], [1, 48, 90, 102, 163], [1, 48, 90, 102, 163, 399], [3, 164], [3, 164, 53], [3, 164, 53, 400], [3, 164, 53, 400, 125], [3, 164, 53, 400, 125, 3], [3, 164, 53, 400, 125, 3, 401], [7, 402], [7, 402, 403], [7, 402, 403, 72], [7, 402, 403, 72, 36], [7, 402, 403, 72, 36, 9], [7, 402, 403, 72, 36, 9, 404], [161, 101], [161, 101, 2], [161, 101, 2, 165], [161, 101, 2, 165, 9], [161, 101, 2, 165, 9, 52], [161, 101, 2, 165, 9, 52, 10], [161, 101, 2, 165, 9, 52, 10, 405], [9, 166], [9, 166, 149], [9, 166, 149, 1], [9, 166, 149, 1, 72], [9, 166, 149, 1, 72, 2], [9, 166, 149, 1, 72, 2, 162], [9, 102], [9, 102, 34], [9, 102, 34, 406], [9, 102, 34, 406, 167], [9, 102, 34, 406, 167, 10], [9, 102, 34, 406, 167, 10, 407], [3, 408], [3, 408, 9], [3, 408, 9, 409], [3, 408, 9, 409, 2], [3, 408, 9, 409, 2, 40], [8, 54], [8, 54, 5], [8, 54, 5, 84], [8, 54, 5, 84, 7], [8, 54, 5, 84, 7, 30], [8, 54, 5, 84, 7, 30, 410], [3, 411], [3, 411, 9], [3, 411, 9, 77], [3, 411, 9, 77, 73], [3, 411, 9, 77, 73, 16], [3, 411, 9, 77, 73, 16, 168], [2, 17], [2, 17, 412], [2, 17, 412, 169], [2, 17, 412, 169, 170], [3, 37], [3, 37, 20], [3, 37, 20, 171], [3, 37, 20, 171, 102], [3, 37, 20, 171, 102, 9], [3, 37, 20, 171, 102, 9, 413], [20, 171], [20, 171, 9], [20, 171, 9, 10], [20, 171, 9, 10, 414], [20, 171, 9, 10, 414, 3], [20, 171, 9, 10, 414, 3, 415], [1, 48], [1, 48, 1], [1, 48, 1, 48], [1, 48, 1, 48, 24], [1, 48, 1, 48, 24, 172], [1, 48, 1, 48, 24, 172, 2], [1, 48, 1, 48, 24, 172, 2, 416], [5, 84], [5, 84, 155], [5, 84, 155, 1], [5, 84, 155, 1, 417], [5, 84, 155, 1, 417, 3], [5, 84, 155, 1, 417, 3, 418], [1, 167], [1, 167, 10], [1, 167, 10, 419], [1, 167, 10, 419, 48], [1, 167, 10, 419, 48, 15], [1, 167, 10, 419, 48, 15, 62], [1, 103], [1, 103, 24], [1, 103, 24, 420], [1, 103, 24, 420, 169], [1, 103, 24, 420, 169, 163], [3, 66], [3, 66, 421], [3, 66, 421, 422], [3, 66, 421, 422, 1], [3, 66, 421, 422, 1, 104], [3, 66, 421, 422, 1, 104, 2], [3, 66, 421, 422, 1, 104, 2, 1], [3, 66, 421, 422, 1, 104, 2, 1, 104], [65, 133], [65, 133, 173], [65, 133, 173, 6], [65, 133, 173, 6, 131], [65, 133, 173, 6, 131, 12], [65, 133, 173, 6, 131, 12, 38], [65, 133, 173, 6, 131, 12, 38, 2], [65, 133, 173, 6, 131, 12, 38, 2, 423], [3, 173], [3, 173, 6], [3, 173, 6, 424], [3, 173, 6, 424, 12], [3, 173, 6, 424, 12, 56], [3, 173, 6, 424, 12, 56, 425], [3, 173, 6, 424, 12, 56, 425, 27], [3, 173, 6, 424, 12, 56, 425, 27, 426], [5, 427], [5, 427, 2], [5, 427, 2, 428], [5, 427, 2, 428, 429], [5, 427, 2, 428, 429, 174], [5, 427, 2, 428, 429, 174, 115], [5, 427, 2, 428, 429, 174, 115, 1], [5, 427, 2, 428, 429, 174, 115, 1, 103], [56, 164], [56, 164, 7], [56, 164, 7, 104], [56, 164, 7, 104, 430], [56, 164, 7, 104, 430, 7], [56, 164, 7, 104, 430, 7, 18], [56, 164, 7, 104, 430, 7, 18, 27], [8, 431], [8, 431, 3], [8, 431, 3, 432], [8, 431, 3, 432, 160], [8, 431, 3, 432, 160, 8], [8, 431, 3, 432, 160, 8, 433], [8, 431, 3, 432, 160, 8, 433, 434], [8, 431, 3, 432, 160, 8, 433, 434, 50], [435, 436], [435, 436, 2], [435, 436, 2, 134], [435, 436, 2, 134, 96], [435, 436, 2, 134, 96, 174], [435, 436, 2, 134, 96, 174, 8], [435, 436, 2, 134, 96, 174, 8, 10], [8, 437], [8, 437, 2], [8, 437, 2, 17], [8, 437, 2, 17, 1], [8, 437, 2, 17, 1, 103], [8, 437, 2, 17, 1, 103, 38], [8, 437, 2, 17, 1, 103, 38, 95], [2, 105], [2, 105, 16], [2, 105, 16, 438], [2, 105, 16, 438, 9], [2, 105, 16, 438, 9, 24], [2, 105, 16, 438, 9, 24, 66], [2, 105, 16, 438, 9, 24, 66, 175], [3, 15], [3, 15, 12], [3, 15, 12, 68], [3, 15, 12, 68, 132], [3, 15, 12, 68, 132, 3], [3, 15, 12, 68, 132, 3, 137], [3, 15, 12, 68, 132, 3, 137, 53], [3, 15, 12, 68, 132, 3, 137, 53, 44], [8, 439], [8, 439, 45], [8, 439, 45, 4], [8, 439, 45, 4, 43], [8, 439, 45, 4, 43, 106], [8, 439, 45, 4, 43, 106, 63], [8, 439, 45, 4, 43, 106, 63, 44], [8, 439, 45, 4, 43, 106, 63, 44, 22], [63, 440], [63, 440, 441], [63, 440, 441, 442], [63, 440, 441, 442, 443], [63, 440, 441, 442, 443, 33], [63, 440, 441, 442, 443, 33, 5], [63, 440, 441, 442, 443, 33, 5, 72], [36, 444], [36, 444, 29], [36, 444, 29, 47], [36, 444, 29, 47, 445], [36, 444, 29, 47, 445, 3], [36, 444, 29, 47, 445, 3, 32], [36, 444, 29, 47, 445, 3, 32, 446], [4, 166], [4, 166, 107], [4, 166, 107, 6], [4, 166, 107, 6, 11], [4, 166, 107, 6, 11, 14], [4, 166, 107, 6, 11, 14, 44], [4, 166, 107, 6, 11, 14, 44, 22], [4, 447], [4, 447, 45], [4, 447, 45, 4], [4, 447, 45, 4, 10], [4, 447, 45, 4, 10, 448], [4, 447, 45, 4, 10, 448, 16], [4, 447, 45, 4, 10, 448, 16, 5], [4, 447, 45, 4, 10, 448, 16, 5, 449], [2, 106], [2, 106, 11], [2, 106, 11, 176], [2, 106, 11, 176, 41], [2, 106, 11, 176, 41, 154], [2, 106, 11, 176, 41, 154, 2], [2, 106, 11, 176, 41, 154, 2, 40], [2, 106, 11, 176, 41, 154, 2, 40, 7], [2, 106, 11, 176, 41, 154, 2, 40, 7, 450], [3, 451], [3, 451, 1], [3, 451, 1, 452], [3, 451, 1, 452, 175], [3, 451, 1, 452, 175, 1], [3, 451, 1, 452, 175, 1, 129], [3, 451, 1, 452, 175, 1, 129, 29], [3, 451, 1, 452, 175, 1, 129, 29, 453], [36, 1], [36, 1, 145], [36, 1, 145, 454], [36, 1, 145, 454, 455], [36, 1, 145, 454, 455, 55], [36, 1, 145, 454, 455, 55, 456], [36, 1, 145, 454, 455, 55, 456, 100], [36, 1, 145, 454, 455, 55, 456, 100, 1], [36, 1, 145, 454, 455, 55, 456, 100, 1, 457], [71, 177], [71, 177, 2], [71, 177, 2, 32], [71, 177, 2, 32, 11], [71, 177, 2, 32, 11, 60], [71, 177, 2, 32, 11, 60, 9], [71, 177, 2, 32, 11, 60, 9, 45], [71, 177, 2, 32, 11, 60, 9, 45, 4], [71, 177, 2, 32, 11, 60, 9, 45, 4, 10], [56, 98], [56, 98, 71], [56, 98, 71, 177], [56, 98, 71, 177, 2], [56, 98, 71, 177, 2, 178], [56, 98, 71, 177, 2, 178, 63], [56, 98, 71, 177, 2, 178, 63, 22], [56, 98, 71, 177, 2, 178, 63, 22, 458], [14, 459], [14, 459, 178], [14, 459, 178, 460], [14, 459, 178, 460, 70], [14, 459, 178, 460, 70, 461], [14, 459, 178, 460, 70, 461, 16], [14, 459, 178, 460, 70, 461, 16, 11], [462, 1], [462, 1, 463], [462, 1, 463, 6], [462, 1, 463, 6, 464], [462, 1, 463, 6, 464, 465], [1, 466], [1, 466, 20], [1, 466, 20, 467], [1, 466, 20, 467, 468], [1, 466, 20, 467, 468, 85], [1, 466, 20, 467, 468, 85, 38], [1, 466, 20, 467, 468, 85, 38, 2], [4, 469], [4, 469, 23], [4, 469, 23, 158], [4, 469, 23, 158, 19], [4, 469, 23, 158, 19, 1], [4, 469, 23, 158, 19, 1, 107], [4, 469, 23, 158, 19, 1, 107, 6], [4, 469, 23, 158, 19, 1, 107, 6, 470], [37, 179], [37, 179, 51], [37, 179, 51, 471], [37, 179, 51, 471, 472], [3, 473], [3, 473, 6], [3, 473, 6, 474], [3, 473, 6, 474, 475], [3, 473, 6, 474, 475, 6], [3, 473, 6, 474, 475, 6, 476], [3, 473, 6, 474, 475, 6, 476, 70], [3, 473, 6, 474, 475, 6, 476, 70, 179], [51, 477], [51, 477, 6], [51, 477, 6, 478], [51, 477, 6, 478, 99], [51, 477, 6, 478, 99, 6], [51, 477, 6, 478, 99, 6, 52], [51, 477, 6, 478, 99, 6, 52, 10], [51, 477, 6, 478, 99, 6, 52, 10, 479], [51, 477, 6, 478, 99, 6, 52, 10, 479, 4], [51, 477, 6, 478, 99, 6, 52, 10, 479, 4, 180], [27, 480], [27, 480, 73], [27, 480, 73, 2], [27, 480, 73, 2, 17], [27, 480, 73, 2, 17, 181], [27, 480, 73, 2, 17, 181, 481], [4, 15], [4, 15, 89], [4, 15, 89, 165], [4, 15, 89, 165, 126], [4, 15, 89, 165, 126, 482], [4, 15, 89, 165, 126, 482, 26], [4, 15, 89, 165, 126, 482, 26, 43], [4, 15, 89, 165, 126, 482, 26, 43, 483], [25, 108], [25, 108, 39], [25, 108, 39, 105], [25, 108, 39, 105, 11], [25, 108, 39, 105, 11, 42], [25, 15], [25, 15, 105], [21, 159], [21, 159, 484], [21, 159, 484, 157], [21, 159, 484, 157, 69], [21, 159, 484, 157, 69, 2], [21, 159, 484, 157, 69, 2, 108], [21, 159, 484, 157, 69, 2, 108, 25], [21, 159, 484, 157, 69, 2, 108, 25, 32], [21, 159, 484, 157, 69, 2, 108, 25, 32, 11], [109, 26], [109, 26, 485], [109, 26, 485, 7], [109, 26, 485, 7, 31], [109, 26, 485, 7, 31, 7], [109, 26, 485, 7, 31, 7, 486], [109, 26, 485, 7, 31, 7, 486, 34], [109, 26, 485, 7, 31, 7, 486, 34, 487], [18, 488], [18, 488, 489], [18, 488, 489, 78], [18, 488, 489, 78, 6], [18, 488, 489, 78, 6, 182], [18, 488, 489, 78, 6, 182, 21], [18, 488, 489, 78, 6, 182, 21, 12], [18, 488, 489, 78, 6, 182, 21, 12, 5], [18, 488, 489, 78, 6, 182, 21, 12, 5, 490], [491, 492], [491, 492, 3], [491, 492, 3, 79], [491, 492, 3, 79, 493], [491, 492, 3, 79, 493, 182], [29, 183], [29, 183, 3], [29, 183, 3, 183], [29, 183, 3, 183, 1], [29, 183, 3, 183, 1, 494], [29, 183, 3, 183, 1, 494, 8], [29, 183, 3, 183, 1, 494, 8, 495], [29, 183, 3, 183, 1, 494, 8, 495, 496], [29, 183, 3, 183, 1, 494, 8, 495, 496, 2], [70, 497], [70, 497, 2], [70, 497, 2, 94], [70, 497, 2, 94, 498], [70, 497, 2, 94, 498, 31], [70, 497, 2, 94, 498, 31, 499], [70, 497, 2, 94, 498, 31, 499, 13], [19, 5], [19, 5, 500], [19, 5, 500, 501], [19, 5, 500, 501, 18], [19, 5, 500, 501, 18, 43], [19, 5, 500, 501, 18, 43, 68], [4, 107], [4, 107, 23], [4, 107, 23, 34], [4, 107, 23, 34, 21], [4, 107, 23, 34, 21, 502], [4, 107, 23, 34, 21, 502, 27], [4, 107, 23, 34, 21, 502, 27, 2], [4, 107, 23, 34, 21, 502, 27, 2, 94], [4, 107, 23, 34, 21, 502, 27, 2, 94, 23], [503, 504], [503, 504, 1], [503, 504, 1, 109], [503, 504, 1, 109, 28], [503, 504, 1, 109, 28, 1], [503, 504, 1, 109, 28, 1, 170], [503, 504, 1, 109, 28, 1, 170, 505], [503, 504, 1, 109, 28, 1, 170, 505, 42], [3, 101], [3, 101, 35], [3, 101, 35, 28], [3, 101, 35, 28, 1], [3, 101, 35, 28, 1, 168], [3, 101, 35, 28, 1, 168, 8], [3, 101, 35, 28, 1, 168, 8, 180], [3, 101, 35, 28, 1, 168, 8, 180, 5], [3, 101, 35, 28, 1, 168, 8, 180, 5, 74], [5, 74], [5, 74, 44], [5, 74, 44, 22], [5, 74, 44, 22, 506], [5, 74, 44, 22, 506, 52], [5, 74, 44, 22, 506, 52, 184], [8, 507], [8, 507, 31], [8, 507, 31, 508], [8, 507, 31, 508, 6], [8, 507, 31, 508, 6, 509], [8, 507, 31, 508, 6, 509, 18], [8, 507, 31, 508, 6, 509, 18, 2], [8, 507, 31, 508, 6, 509, 18, 2, 39], [5, 74], [5, 74, 22], [5, 74, 22, 43], [5, 74, 22, 43, 38], [5, 74, 22, 43, 38, 2], [5, 74, 22, 43, 38, 2, 185], [5, 74, 22, 43, 38, 2, 185, 186], [37, 4], [37, 4, 10], [37, 4, 10, 510], [37, 4, 10, 510, 4], [37, 4, 10, 510, 4, 24], [37, 4, 10, 510, 4, 24, 91], [37, 4, 10, 510, 4, 24, 91, 172], [2, 108], [2, 108, 96], [2, 108, 96, 32], [2, 108, 96, 32, 11], [2, 108, 96, 32, 11, 91], [2, 108, 96, 32, 11, 91, 511], [2, 108, 96, 32, 11, 91, 511, 512], [21, 185], [21, 185, 186], [21, 185, 186, 513], [21, 185, 186, 513, 23], [21, 185, 186, 513, 23, 187], [21, 185, 186, 513, 23, 187, 188], [1, 514], [1, 514, 6], [1, 514, 6, 109], [1, 514, 6, 109, 4], [1, 514, 6, 109, 4, 57], [1, 514, 6, 109, 4, 57, 515], [1, 514, 6, 109, 4, 57, 515, 110], [1, 514, 6, 109, 4, 57, 515, 110, 111], [16, 18], [16, 18, 10], [16, 18, 10, 29], [16, 18, 10, 29, 26], [16, 18, 10, 29, 26, 516], [16, 18, 10, 29, 26, 516, 50], [16, 18, 10, 29, 26, 516, 50, 184], [110, 111], [110, 111, 23], [110, 111, 23, 187], [110, 111, 23, 187, 188], [110, 111, 23, 187, 188, 1], [110, 111, 23, 187, 188, 1, 517], [110, 111, 23, 187, 188, 1, 517, 518], [4, 57], [4, 57, 17], [4, 57, 17, 519], [4, 57, 17, 519, 2], [4, 57, 17, 519, 2, 520], [4, 57, 17, 519, 2, 520, 1], [4, 57, 17, 519, 2, 520, 1, 521], [43, 522], [43, 522, 7], [43, 522, 7, 523], [43, 522, 7, 523, 16], [43, 522, 7, 523, 16, 99], [43, 522, 7, 523, 16, 99, 22], [43, 522, 7, 523, 16, 99, 22, 33], [43, 522, 7, 523, 16, 99, 22, 33, 524], [525, 526], [525, 526, 527], [525, 526, 527, 528], [525, 526, 527, 528, 529], [15, 530], [15, 530, 73], [15, 530, 73, 28], [15, 530, 73, 28, 2], [15, 530, 73, 28, 2, 531], [15, 530, 73, 28, 2, 531, 176], [15, 530, 73, 28, 2, 531, 176, 73], [5, 74], [5, 74, 44], [5, 74, 44, 22], [5, 74, 44, 22, 4], [5, 74, 44, 22, 4, 532], [5, 74, 44, 22, 4, 532, 60], [5, 74, 44, 22, 4, 532, 60, 4], [5, 74, 44, 22, 4, 532, 60, 4, 24], [181, 110], [181, 110, 111], [181, 110, 111, 98], [181, 110, 111, 98, 2], [181, 110, 111, 98, 2, 533], [181, 110, 111, 98, 2, 533, 49], [181, 110, 111, 98, 2, 533, 49, 100], [181, 110, 111, 98, 2, 533, 49, 100, 106], [14, 92], [14, 92, 17], [14, 92, 17, 534], [14, 92, 17, 534, 20], [14, 92, 17, 534, 20, 5], [14, 92, 17, 534, 20, 5, 535], [14, 92, 17, 534, 20, 5, 535, 536], [34, 537], [34, 537, 4], [34, 537, 4, 538], [34, 537, 4, 538, 120], [34, 537, 4, 538, 120, 13], [34, 537, 4, 538, 120, 13, 7], [34, 537, 4, 538, 120, 13, 7, 5], [34, 537, 4, 538, 120, 13, 7, 5, 539], [4, 540], [4, 540, 541], [4, 540, 541, 189], [4, 540, 541, 189, 4], [4, 540, 541, 189, 4, 15], [4, 540, 541, 189, 4, 15, 542], [4, 540, 541, 189, 4, 15, 542, 25], [4, 540, 541, 189, 4, 15, 542, 25, 13], [7, 189], [7, 189, 25], [7, 189, 25, 543], [7, 189, 25, 543, 5], [7, 189, 25, 543, 5, 544], [7, 189, 25, 543, 5, 544, 44]]\n"
          ]
        }
      ],
      "source": [
        "print(input_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdrNuIsQ0dea",
        "outputId": "f18f029b-1ae8-4bf0-deb8-6027f0328f4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n"
          ]
        }
      ],
      "source": [
        "#prints this maximum sequence length, which is needed for padding.\n",
        "max_seq_length = max(len(x) for x in input_seq)\n",
        "print(max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPXmX69T0hcg",
        "outputId": "6adaddca-4335-48d6-d770-1067919a0081"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0   0   0 ...   0 112 113]\n",
            " [  0   0   0 ... 112 113 114]\n",
            " [  0   0   0 ... 113 114   7]\n",
            " ...\n",
            " [  0   0   0 ...  25 543   5]\n",
            " [  0   0   0 ... 543   5 544]\n",
            " [  0   0   0 ...   5 544  44]]\n"
          ]
        }
      ],
      "source": [
        "# Padding the sequences and converting them to array\n",
        "input_seq = np.array(pad_sequences(input_seq, maxlen=max_seq_length, padding='pre'))\n",
        "print(input_seq)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrKH-eUC0lFD",
        "outputId": "aec2116d-498a-4bff-aac7-296e4c87cd3e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "xs:  [[  0   0   0 ...   0   0 112]\n",
            " [  0   0   0 ...   0 112 113]\n",
            " [  0   0   0 ... 112 113 114]\n",
            " ...\n",
            " [  0   0   0 ... 189  25 543]\n",
            " [  0   0   0 ...  25 543   5]\n",
            " [  0   0   0 ... 543   5 544]]\n",
            "labels: [113 114   7 ...   5 544  44]\n"
          ]
        }
      ],
      "source": [
        "# Taking xs and labels to train the model.\n",
        "\n",
        "xs = input_seq[:, :-1]        # xs contains every word in sentence except the last one because we are using this value to predict the y value\n",
        "labels = input_seq[:, -1]     # labels contains only the last word of the sentence which will help in hot encoding the y value in next step\n",
        "print(\"xs: \",xs)\n",
        "print(\"labels:\",labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nWaAKP6z0rNS"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXxkntt20tKm",
        "outputId": "71e2f559-98bc-43ea-986b-377c39306ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ],
      "source": [
        "# one-hot encoding the labels according to the vocab size\n",
        "\n",
        "# The matrix is square matrix of the size of vocab_size. Each row will denote a label and it will have\n",
        "# a single +ve value(i.e 1) for that label and other values will be zero.\n",
        "\n",
        "ys = to_categorical(labels, num_classes=vocab_size)\n",
        "print(ys)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "id": "7uIVLKUa0xll",
        "outputId": "43f522b6-6308-473e-e68f-27c1086eeb95"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Input: This is a Keras tensor object that is used to define the shape and data type of the inputs to your model.\\nDense: This is a fully connected neural network layer. It represents a linear operation in which every input is connected to every output by a weight.\\nEmbedding: This layer is used to create word embeddings, which are dense vector representations of words in a high-dimensional space. It is commonly used in natural language processing tasks to capture semantic relationships between words.\\nLSTM: This is a Long Short-Term Memory layer, which is a type of recurrent neural network (RNN) layer. It is capable of learning long-term dependencies in sequence data.\\nDropout: This layer applies dropout regularization to the input. Dropout is a technique used to prevent overfitting by randomly setting a fraction of input units to zero during training.\\nBidirectional: This wrapper allows the LSTM layer to process input sequences in both forward and backward directions. It helps the model to capture dependencies in both past and future contexts.\\nGlobalMaxPooling1D: This layer performs max pooling operation across the entire sequence dimension. It reduces the sequence dimensionality while retaining the most important information.\\nModel: This class allows you to instantiate a Keras model by specifying its input and output layers.\\nAdam: This is an optimization algorithm, specifically Adam, which is widely used for training neural networks. It adapts the learning rate during training.\\nSequential: This is a Keras model type that allows you to build models layer by layer sequentially.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Embedding, LSTM, Dropout, Bidirectional, GlobalMaxPooling1D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# \"\"\"Input: This is a Keras tensor object that is used to define the shape and data type of the inputs to your model.\n",
        "# Dense: This is a fully connected neural network layer. It represents a linear operation in which every input is connected to every output by a weight.\n",
        "# Embedding: This layer is used to create word embeddings, which are dense vector representations of words in a high-dimensional space. It is commonly used in natural language processing tasks to capture semantic relationships between words.\n",
        "# LSTM: This is a Long Short-Term Memory layer, which is a type of recurrent neural network (RNN) layer. It is capable of learning long-term dependencies in sequence data.\n",
        "# Dropout: This layer applies dropout regularization to the input. Dropout is a technique used to prevent overfitting by randomly setting a fraction of input units to zero during training.\n",
        "# Bidirectional: This wrapper allows the LSTM layer to process input sequences in both forward and backward directions. It helps the model to capture dependencies in both past and future contexts.\n",
        "# GlobalMaxPooling1D: This layer performs max pooling operation across the entire sequence dimension. It reduces the sequence dimensionality while retaining the most important information.\n",
        "# Model: This class allows you to instantiate a Keras model by specifying its input and output layers.\n",
        "# Adam: This is an optimization algorithm, specifically Adam, which is widely used for training neural networks. It adapts the learning rate during training.\n",
        "# Sequential: This is a Keras model type that allows you to build models layer by layer sequentially.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CVSHpdZ03ji"
      },
      "outputs": [],
      "source": [
        "# using the functional APIs of keras to define the model\n",
        "\n",
        "i = Input(shape=(max_seq_length - 1, ))                           # using 1 less value becasuse we are preserving the last value for predicted word\n",
        "x = Embedding(vocab_size, 124)(i)\n",
        "x = Dropout(0.2)(x)\n",
        "x = LSTM(520, return_sequences=True)(x)\n",
        "x = Bidirectional(layer=LSTM(340, return_sequences=True))(x)\n",
        "x = GlobalMaxPooling1D()(x)\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dense(vocab_size, activation='softmax')(x)\n",
        "\n",
        "model = Model(i,x)\n",
        "\n",
        "# using the pipeline method of sequential to define a model\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(vocab_size, 124, input_length=max_seq_length-1))\n",
        "# model.add(Dropout(0.2))\n",
        "# model.add(LSTM(520, return_sequences=True))\n",
        "# model.add(Bidirectional(LSTM(340, return_sequences=True)))\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "# model.add(Dense(1024, activation='relu'))\n",
        "# model.add(Dense(vocab_size, activation='softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vugczS_06xz",
        "outputId": "26dd1ff1-001b-4731-f38b-40d9198f76bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer=Adam(lr=0.001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "qhfo5cXr0-8t",
        "outputId": "6eeefaa3-07ab-414b-d11c-9d59b4052504"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 25s 440ms/step - loss: 6.1536 - accuracy: 0.0467\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 15s 393ms/step - loss: 5.8212 - accuracy: 0.0384\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 15s 389ms/step - loss: 5.7448 - accuracy: 0.0409\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 15s 400ms/step - loss: 5.7258 - accuracy: 0.0459\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 15s 390ms/step - loss: 5.7130 - accuracy: 0.0467\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 16s 413ms/step - loss: 5.6878 - accuracy: 0.0476\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 15s 384ms/step - loss: 5.5948 - accuracy: 0.0417\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 15s 391ms/step - loss: 5.4141 - accuracy: 0.0518\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 15s 388ms/step - loss: 5.2631 - accuracy: 0.0534\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 15s 396ms/step - loss: 5.1399 - accuracy: 0.0693\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 15s 406ms/step - loss: 5.0028 - accuracy: 0.0634\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 14s 376ms/step - loss: 4.8513 - accuracy: 0.0793\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 14s 369ms/step - loss: 4.6777 - accuracy: 0.0735\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 15s 380ms/step - loss: 4.4866 - accuracy: 0.0985\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 14s 362ms/step - loss: 4.3210 - accuracy: 0.0943\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 14s 377ms/step - loss: 4.1067 - accuracy: 0.1160\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 15s 389ms/step - loss: 3.9197 - accuracy: 0.1336\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 16s 413ms/step - loss: 3.6853 - accuracy: 0.1611\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 16s 416ms/step - loss: 3.4770 - accuracy: 0.1745\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 15s 399ms/step - loss: 3.2452 - accuracy: 0.2062\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 15s 386ms/step - loss: 3.0342 - accuracy: 0.2287\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 15s 395ms/step - loss: 2.7999 - accuracy: 0.2888\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 15s 389ms/step - loss: 2.5300 - accuracy: 0.3239\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 15s 385ms/step - loss: 2.3213 - accuracy: 0.3606\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 14s 382ms/step - loss: 2.0888 - accuracy: 0.4265\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 15s 394ms/step - loss: 1.9454 - accuracy: 0.4574\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 15s 405ms/step - loss: 1.7104 - accuracy: 0.5242\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 17s 434ms/step - loss: 1.5744 - accuracy: 0.5467\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 15s 382ms/step - loss: 1.4333 - accuracy: 0.5876\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 15s 387ms/step - loss: 1.2982 - accuracy: 0.6235\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 14s 382ms/step - loss: 1.2361 - accuracy: 0.6377\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 15s 391ms/step - loss: 1.0729 - accuracy: 0.6978\n",
            "Epoch 33/100\n",
            "27/38 [====================>.........] - ETA: 3s - loss: 0.8989 - accuracy: 0.7396"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3f38c4ef23ec>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1805\u001b[0m                         ):\n\u001b[1;32m   1806\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1807\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1808\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    831\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 832\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    833\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    834\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    866\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    867\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 868\u001b[0;31m       return tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    869\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1321\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1322\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1485\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1486\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1487\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1488\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "r = model.fit(xs,ys,epochs=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ZhajcUIe6MCt",
        "outputId": "f8396bee-3a34-41cb-cd8c-0ea6969436df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7858c4bfe260>]"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Evaluating the model on accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(r.history['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlsZeGho6W5a"
      },
      "outputs": [],
      "source": [
        "def predict_words(seed, no_words):\n",
        "  for i in range(no_words):\n",
        "    token_list = tokenizer.texts_to_sequences([seed])[0]\n",
        "    token_list = pad_sequences([token_list], maxlen=max_seq_length-1, padding='pre')\n",
        "    predicted = np.argmax(model.predict(token_list), axis=1)\n",
        "\n",
        "    new_word = ''\n",
        "\n",
        "    for word, index in tokenizer.word_index.items():\n",
        "      if predicted == index:\n",
        "        new_word = word\n",
        "        break\n",
        "    seed += \" \" + new_word\n",
        "  print(seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLYx9tYX6bC2",
        "outputId": "34075df4-a198-4d80-85d9-a8f5d5de3929"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "i am feeling good today where its likely to go better brim clumps had poise had fallen apiece had fallen all meant to be— had strip three cents all them more apiece apiece apiece know me know i stay come back them them over over again them over again if i was tempted for a\n"
          ]
        }
      ],
      "source": [
        "seed_text = 'i am feeling good today'\n",
        "next_words = 50\n",
        "\n",
        "predict_words(seed_text, next_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ejWWjr6fR_",
        "outputId": "d5f05e25-34ac-4499-9b22-6ec14268d3d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ],
      "source": [
        "# saving the model\n",
        "\n",
        "model.save('poem_generator.h5') # Will create a HDF5 file of the model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}